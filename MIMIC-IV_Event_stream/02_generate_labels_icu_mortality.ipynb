{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate labels: ICU mortality (binary)\n\n## Purpose\nGenerate ICU mortality labels using the EHRSHOT/FEMR labeler for each split (train/tuning/held_out).\n\n## Inputs\n- FEMR database at <BASE>/<split>/extract/\n- Label output directory <BASE>/<split>/femr_labels/\n\n## Outputs\n- Labels at: <BASE>/<split>/femr_labels/mimic_icu_mortality/*.csv (including all_labels.csv depending on your flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957372e9-93e7-460c-8700-ce1f6232881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from multiprocessing import Pool, Manager\n",
    "from loguru import logger\n",
    "from typing import List, Dict\n",
    "\n",
    "# Core femr and ehrshot imports\n",
    "import femr.datasets\n",
    "from femr.labelers import LabeledPatients, Label\n",
    "from ehrshot.labelers.mimic import Mimic_ICUEventStreamMortalityLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc9c49-4c80-42bf-bdc9-d222130adeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Please modify your configuration here ---\n",
    "\n",
    "# 1. INPUT: Path to your successfully created FEMR database extract\n",
    "PATH_TO_FEMR_DATABASE = \"/root/autodl-tmp/femr/held_out/extract\" \n",
    "\n",
    "# 2. OUTPUT: A directory where the generated label files will be saved\n",
    "PATH_TO_OUTPUT_DIR = \"/root/autodl-tmp/femr/held_out/femr_labels/\"\n",
    "\n",
    "# 3. TASK NAME: A subdirectory will be created with this name\n",
    "TASK_NAME = \"mimic_icu_mortality\"\n",
    "\n",
    "# 4. PARAMETERS\n",
    "# Number of CPU cores to use for parallel processing\n",
    "NUM_PROCESSES = 15\n",
    "# Set to True if you want to randomly sample only one ICU stay per patient.\n",
    "# Set to False to generate a label for every ICU stay.\n",
    "IS_SAMPLE_ONE_LABEL_PER_PATIENT = False\n",
    "\n",
    "# --- End of configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d45cc-c67d-4ab4-94e9-17043b4347d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically create the full path for the output file\n",
    "PATH_TO_TASK_OUTPUT_DIR = os.path.join(PATH_TO_OUTPUT_DIR, TASK_NAME)\n",
    "PATH_TO_OUTPUT_FILE = os.path.join(PATH_TO_TASK_OUTPUT_DIR, \"labeled_patients.csv\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(PATH_TO_TASK_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "path_to_log_file = os.path.join(PATH_TO_TASK_OUTPUT_DIR, 'info.log')\n",
    "if os.path.exists(path_to_log_file):\n",
    "    os.remove(path_to_log_file)\n",
    "logger.add(path_to_log_file, level=\"INFO\")\n",
    "\n",
    "logger.info(f\"Task: {TASK_NAME}\")\n",
    "logger.info(f\"FEMR Database Path: {PATH_TO_FEMR_DATABASE}\")\n",
    "logger.info(f\"Output Directory: {PATH_TO_TASK_OUTPUT_DIR}\")\n",
    "logger.info(f\"Sample one label per patient: {IS_SAMPLE_ONE_LABEL_PER_PATIENT}\")\n",
    "logger.info(f\"Number of threads: {NUM_PROCESSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cd911-a173-4378-833b-bdc2a4915566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labeled_patients_to_csv(labeled_patients: LabeledPatients, path_to_csv: str):\n",
    "    \"\"\"Converts a LabeledPatients object to a pandas DataFrame and saves it as a CSV.\"\"\"\n",
    "    rows = []\n",
    "    for patient_id, labels in labeled_patients.items():\n",
    "        for l in labels:\n",
    "            rows.append((patient_id, l.time, l.value, labeled_patients.labeler_type))\n",
    "    df = pd.DataFrame(rows, columns=['patient_id', 'prediction_time', 'value', 'label_type'])\n",
    "    df = df.sort_values(['patient_id', 'prediction_time', 'value'])\n",
    "    df.to_csv(path_to_csv, index=False)\n",
    "    logger.success(f\"Successfully saved {len(df)} labels to {path_to_csv}\")\n",
    "\n",
    "# This function is needed for the IS_SAMPLE_ONE_LABEL_PER_PATIENT logic\n",
    "def process_patient_ids_for_sampling(args):\n",
    "    \"\"\"Processes a subset of patient IDs to sample one label per patient.\"\"\"\n",
    "    pid_subset, labeled_patients_dict, path_to_database = args\n",
    "    local_results = {}\n",
    "    database = femr.datasets.PatientDatabase(path_to_database)\n",
    "    labeled_patients = LabeledPatients.from_dict(labeled_patients_dict)\n",
    "\n",
    "    for pid in pid_subset:\n",
    "        random.seed(int(pid))\n",
    "        labels = labeled_patients.get_labels_from_patient_idx(pid)\n",
    "        \n",
    "        # Filter out labels that occur for patients <= 18 yrs of age\n",
    "        if not database[pid].events:\n",
    "            continue\n",
    "        birth_year = database[pid].events[0].start.year\n",
    "        \n",
    "        valid_labels = [l for l in labels if (l.time.year - birth_year) >= 18]\n",
    "        \n",
    "        if not valid_labels:\n",
    "            local_results[pid] = []\n",
    "        elif len(valid_labels) == 1:\n",
    "            local_results[pid] = valid_labels\n",
    "        else:\n",
    "            local_results[pid] = [random.choice(valid_labels)]\n",
    "            \n",
    "    return local_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d7e55-624d-41d5-b749-b37b6cc12122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PatientDatabase and Ontology\n",
    "logger.info(\"Start | Loading PatientDatabase and Ontology\")\n",
    "database = femr.datasets.PatientDatabase(PATH_TO_FEMR_DATABASE)\n",
    "ontology = database.get_ontology()\n",
    "logger.info(\"Finish | Loading PatientDatabase and Ontology\")\n",
    "\n",
    "# Initialize the labeler for ICU mortality\n",
    "labeler = Mimic_ICUEventStreamMortalityLabeler(ontology)\n",
    "\n",
    "# Apply the labeler to the database\n",
    "logger.info(\"Start | Applying labeler to all patients\")\n",
    "labeled_patients = labeler.apply(\n",
    "    path_to_patient_database=PATH_TO_FEMR_DATABASE,\n",
    "    num_threads=NUM_PROCESSES,\n",
    ")\n",
    "logger.info(\"Finish | Applying labeler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bba4be-6789-4690-916d-ba53acd20aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Randomly sample one label per patient\n",
    "if IS_SAMPLE_ONE_LABEL_PER_PATIENT:\n",
    "    logger.info(\"Start | Sampling one label per patient\")\n",
    "    pids = list(labeled_patients.keys())\n",
    "    pid_subsets = [pids[i::NUM_PROCESSES] for i in range(NUM_PROCESSES)]\n",
    "    \n",
    "    # We pass a dictionary representation of labeled_patients to avoid pickling issues\n",
    "    labeled_patients_dict = labeled_patients.to_dict()\n",
    "\n",
    "    with Pool(NUM_PROCESSES) as pool:\n",
    "        results_list = list(tqdm(\n",
    "            pool.imap(\n",
    "                process_patient_ids_for_sampling, \n",
    "                [(subset, labeled_patients_dict, PATH_TO_FEMR_DATABASE) for subset in pid_subsets]\n",
    "            ), \n",
    "            total=len(pid_subsets),\n",
    "            desc=\"Sampling labels\"\n",
    "        ))\n",
    "    \n",
    "    # Combine results from all processes\n",
    "    combined_results = {k: v for d in results_list for k, v in d.items()}\n",
    "    labeled_patients = LabeledPatients(combined_results, labeler_type=labeler.get_labeler_type())\n",
    "    logger.info(\"Finish | Sampling one label per patient\")\n",
    "\n",
    "# Force labels to be minute-level resolution for FEMR compatibility\n",
    "logger.info(\"Start | Adjusting label timestamps to minute-level resolution\")\n",
    "for patient_id, labels in labeled_patients.items():\n",
    "    new_labels = [Label(time=l.time.replace(second=0, microsecond=0), value=l.value) for l in labels]\n",
    "    labeled_patients[patient_id] = new_labels\n",
    "logger.info(\"Finish | Adjusting label timestamps\")\n",
    "\n",
    "# Save the final labeled patients object\n",
    "logger.info(f\"Saving final labeled patients to CSV format at {PATH_TO_OUTPUT_FILE}\")\n",
    "save_labeled_patients_to_csv(labeled_patients, PATH_TO_OUTPUT_FILE)\n",
    "\n",
    "# Final logging of statistics\n",
    "logger.info(\"--- Final Label Statistics ---\")\n",
    "num_patients_total = labeled_patients.get_num_patients(is_include_empty_labels=True)\n",
    "num_patients_with_labels = labeled_patients.get_num_patients(is_include_empty_labels=False)\n",
    "num_labels = labeled_patients.get_num_labels()\n",
    "_, label_values,_ = labeled_patients.as_numpy_arrays()\n",
    "num_positive_labels = int(label_values.sum())\n",
    "\n",
    "logger.info(f\"Total # of patients in database: {num_patients_total}\")\n",
    "logger.info(f\"Total # of patients with at least one label: {num_patients_with_labels}\")\n",
    "logger.info(f\"Total # of labels (ICU stays): {num_labels}\")\n",
    "logger.info(f\"Total # of positive labels (deaths): {num_positive_labels}\")\n",
    "if num_labels > 0:\n",
    "    logger.info(f\"Mortality Rate: {num_positive_labels / num_labels:.2%}\")\n",
    "\n",
    "logger.success(\"ðŸŽ‰ Done! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81fd27-4b51-4263-9204-d71411e8efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_patients.as_numpy_arrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9cc40f-084f-4bbd-bc63-09f0c23b86b2",
   "metadata": {},
   "source": [
    "# My Labeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26998fe9-0205-40d2-898e-e1e9991460be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from femr.datasets import PatientDatabase\n",
    "\n",
    "ICU_ADMIT_PREFIX = \"MIMIC/ICU_ADMISSION\"\n",
    "ICU_DISCHARGE_PREFIX = \"MIMIC/ICU_DISCHARGE\"\n",
    "DEATH_CODES = {\"SNOMED/419620001\"}\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kw): return x\n",
    "\n",
    "def summarize_icu_from_femr(path_to_db: str):\n",
    "    db = PatientDatabase(path_to_db)\n",
    "\n",
    "    try:\n",
    "        pids = list(db)  # patient_idï¼ˆMIMIC  subject_idï¼‰\n",
    "    except TypeError:\n",
    "        pids = list(range(len(db)))\n",
    "\n",
    "    n_patients_total = len(pids)\n",
    "    n_patients_any_icu = 0\n",
    "    n_icu_episodes = 0\n",
    "    n_episodes_ge24_no_early_death = 0\n",
    "\n",
    "    for pid in tqdm(pids, desc=\"Scanning ICU\", mininterval=0.5):\n",
    "        patient = db[pid]\n",
    "        evs = sorted(patient.events, key=lambda e: e.start)\n",
    "        n = len(evs)\n",
    "\n",
    "        any_icu = any(\n",
    "            (isinstance(getattr(e, \"code\", None), str) and e.code.startswith(ICU_ADMIT_PREFIX))\n",
    "            for e in evs\n",
    "        )\n",
    "        if any_icu:\n",
    "            n_patients_any_icu += 1\n",
    "\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            code = getattr(evs[i], \"code\", None)\n",
    "            if isinstance(code, str) and code.startswith(ICU_ADMIT_PREFIX):\n",
    "                start_t = evs[i].start\n",
    "\n",
    "                j = i + 1\n",
    "                end_t = None\n",
    "                while j < n:\n",
    "                    cj = getattr(evs[j], \"code\", None)\n",
    "                    if isinstance(cj, str) and cj.startswith(ICU_DISCHARGE_PREFIX):\n",
    "                        end_t = evs[j].start\n",
    "                        break\n",
    "                    j += 1\n",
    "\n",
    "                if end_t is None:\n",
    "                    i += 1\n",
    "                    continue  # ï¼š stay\n",
    "\n",
    "                n_icu_episodes += 1\n",
    "\n",
    "                if (end_t - start_t).total_seconds() >= 24 * 3600:\n",
    "                    t_pred = start_t + timedelta(hours=24)\n",
    "                    early_death = False\n",
    "                    k = i + 1\n",
    "                    while k < j:\n",
    "                        ck = getattr(evs[k], \"code\", None)\n",
    "                        tk = evs[k].start\n",
    "                        if ck in DEATH_CODES and start_t < tk <= t_pred:\n",
    "                            early_death = True\n",
    "                            break\n",
    "                        k += 1\n",
    "                    if not early_death:\n",
    "                        n_episodes_ge24_no_early_death += 1\n",
    "\n",
    "                i = j + 1\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return {\n",
    "        \"n_patients_total\": n_patients_total,\n",
    "        \"n_patients_any_icu\": n_patients_any_icu,  # ICU ï¼ˆï¼‰\n",
    "        \"n_icu_episodes\": n_icu_episodes,  # â†’  ICU\n",
    "        \"n_episodes_ge24_no_early_death\": n_episodes_ge24_no_early_death,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f637985-57e0-4213-b86e-4633a2dab697",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = summarize_icu_from_femr(PATH_TO_FEMR_DATABASE)\n",
    "print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ehr)",
   "language": "python",
   "name": "ehr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}