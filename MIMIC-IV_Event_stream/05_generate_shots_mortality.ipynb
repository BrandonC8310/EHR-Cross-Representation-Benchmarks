{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate few-shot / subsample splits: ICU mortality\n\n## Purpose\nCreate few-shot subsets/splits for ICU mortality experiments.\n\n## Inputs\n- Labels and/or features produced earlier\n\n## Outputs\n- Shot/split files saved to your chosen output directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911b24e-27bf-4433-bad8-f8c4df0fcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import os, csv, json, random\n",
    "from typing import Dict, List, Tuple\n",
    "from femr.labelers import load_labeled_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01f10c-0a09-4ebe-981f-2684f27749ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/root/autodl-tmp/femr\"\n",
    "LABELING_FUNCTION = \"mimic_icu_mortality\"\n",
    "\n",
    "TRAIN_LABELS_DIR   = f\"{ROOT}/train/femr_labels\"\n",
    "TUNING_LABELS_DIR  = f\"{ROOT}/tuning/femr_labels\"\n",
    "HELDOUT_LABELS_DIR = f\"{ROOT}/held_out/femr_labels\"  # #6JSON， split.csv\n",
    "\n",
    "TRAIN_SPLIT_CSV   = f\"{ROOT}/train/split.csv\"\n",
    "TUNING_SPLIT_CSV  = f\"{ROOT}/tuning/split.csv\"\n",
    "HELDOUT_SPLIT_CSV = f\"{ROOT}/held_out/split.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33f719-0408-4ca9-9fe3-9e3019c91a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOT_STRAT = \"few\"  # \"all\"  \"few\"\n",
    "KS = [1, 8, 16, 32, 64, 128, -1]  # SHOT_STRAT=\"few\"\n",
    "N_REPLICATES = 5\n",
    "SEED = 97\n",
    "BALANCE = \"balanced\"  # \"balanced\" =  1:1 ；\"prevalence\" =\n",
    "\n",
    "\n",
    "def _write_split_csv_from_labeled(lp_path: str, out_csv: str, split_name: str):\n",
    "    \"\"\" labeled_patients.csv  patient_id  split（train/val/test）\"\"\"\n",
    "    lp = load_labeled_patients(lp_path)\n",
    "\n",
    "    pid_set = set()\n",
    "    for pid, _labels in lp.items():\n",
    "        pid_set.add(int(pid))\n",
    "    pids = sorted(pid_set)\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    with open(out_csv, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"patient_id\", \"split\"])\n",
    "        for pid in pids:\n",
    "            w.writerow([pid, split_name])\n",
    "\n",
    "    logger.info(f\"[split.csv] {out_csv}: {split_name} = {len(pids)} patients\")\n",
    "\n",
    "\n",
    "def _load_instances(lp_path: str) -> List[Tuple[int, str, int]]:\n",
    "    \"\"\"\n",
    "     labeled_patients.csv， (patient_id, time_iso(), value0/1) \n",
    "    （ ICU =； (pid,time) ）\n",
    "    \"\"\"\n",
    "    lp = load_labeled_patients(lp_path)\n",
    "    assert lp.labeler_type == \"boolean\", f\" boolean ，: {lp.labeler_type}\"\n",
    "    inst = []\n",
    "    seen = set()\n",
    "    for pid, labels in lp.items():\n",
    "        for lab in labels:\n",
    "            t_iso = lab.time.replace(second=0, microsecond=0).isoformat(timespec=\"minutes\")\n",
    "            key = (int(pid), t_iso)\n",
    "            if key in seen:\n",
    "                continue  # ，\n",
    "            seen.add(key)\n",
    "            v = 1 if bool(lab.value) else 0\n",
    "            inst.append((int(pid), t_iso, v))\n",
    "    return inst\n",
    "\n",
    "def _stratified_orders(train_list, seed):\n",
    "    \"\"\"（/）。。\"\"\"\n",
    "    pos = [i for i,(_,_,v) in enumerate(train_list) if v == 1]\n",
    "    neg = [i for i,(_,_,v) in enumerate(train_list) if v == 0]\n",
    "    rng = random.Random(seed); rng.shuffle(pos); rng.shuffle(neg)\n",
    "    return pos, neg\n",
    "\n",
    "def _extend_to_k(order: List[int], k: int) -> List[int]:\n",
    "    \"\"\">=k，；order \"\"\"\n",
    "    if k <= 0: return order[:]\n",
    "    if not order: return []  # 0，\n",
    "    if len(order) >= k: return order[:k]\n",
    "    reps, rem = divmod(k, len(order))\n",
    "    return order * reps + order[:rem]\n",
    "\n",
    "def _build_train_indices(pos_order, neg_order, k, balance=\"balanced\"):\n",
    "    \"\"\" k （balanced / prevalence）（）\"\"\"\n",
    "    if k <= 0:\n",
    "        return pos_order + neg_order\n",
    "\n",
    "    npos, nneg = len(pos_order), len(neg_order)\n",
    "    if balance == \"balanced\":\n",
    "        k_pos = k // 2\n",
    "        k_neg = k - k_pos\n",
    "        if npos == 0: k_pos, k_neg = 0, k\n",
    "        if nneg == 0: k_pos, k_neg = k, 0\n",
    "    else:\n",
    "        tot = max(1, npos + nneg)\n",
    "        prop = npos / tot\n",
    "        k_pos = int(round(k * prop))\n",
    "        k_neg = k - k_pos\n",
    "\n",
    "    pos_take = _extend_to_k(pos_order, k_pos)\n",
    "    neg_take = _extend_to_k(neg_order, k_neg)\n",
    "    return pos_take + neg_take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859920f0-5efc-42e3-8354-a0cf361d886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_lp   = os.path.join(TRAIN_LABELS_DIR,   LABELING_FUNCTION, \"labeled_patients.csv\")\n",
    "tuning_lp  = os.path.join(TUNING_LABELS_DIR,  LABELING_FUNCTION, \"labeled_patients.csv\")\n",
    "heldout_lp = os.path.join(HELDOUT_LABELS_DIR, LABELING_FUNCTION, \"labeled_patients.csv\")\n",
    "\n",
    "assert os.path.exists(train_lp),   f\" {train_lp}\"\n",
    "assert os.path.exists(tuning_lp),  f\" {tuning_lp}\"\n",
    "assert os.path.exists(heldout_lp), f\" {heldout_lp}\"\n",
    "\n",
    "_write_split_csv_from_labeled(train_lp,   TRAIN_SPLIT_CSV,   \"train\")\n",
    "_write_split_csv_from_labeled(tuning_lp,  TUNING_SPLIT_CSV,  \"val\")\n",
    "_write_split_csv_from_labeled(heldout_lp, HELDOUT_SPLIT_CSV, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d663f96-55cf-474f-ad14-02d7188fac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pool = _load_instances(train_lp)   # [(pid, time_iso, y), ...]\n",
    "val_pool   = _load_instances(tuning_lp)\n",
    "\n",
    "logger.info(f\"train ={len(train_pool)}, val ={len(val_pool)}\")\n",
    "\n",
    "train_pids  = [p for p,_,_ in train_pool]\n",
    "train_times = [t for _,t,_ in train_pool]\n",
    "train_vals  = [v for _,_,v in train_pool]\n",
    "val_pids    = [p for p,_,_ in val_pool]\n",
    "val_times   = [t for _,t,_ in val_pool]\n",
    "val_vals    = [v for _,_,v in val_pool]\n",
    "\n",
    "k_list = ([-1] if SHOT_STRAT == \"all\" else sorted(KS))\n",
    "\n",
    "few_shots_dict = { LABELING_FUNCTION: {} }\n",
    "\n",
    "for k in k_list:\n",
    "    few_shots_dict[LABELING_FUNCTION][k] = {}\n",
    "    for rep in range(N_REPLICATES):\n",
    "        pos_order, neg_order = _stratified_orders(train_pool, SEED + rep)\n",
    "        train_idxs = _build_train_indices(pos_order, neg_order, k, BALANCE)\n",
    "        val_idxs   = list(range(len(val_pool)))\n",
    "\n",
    "        entry = {\n",
    "            \"patient_ids_train_k\":  [train_pids[i]            for i in train_idxs],\n",
    "            \"patient_ids_val_k\":    [val_pids[i]              for i in val_idxs],\n",
    "            \"label_times_train_k\":  [train_times[i]           for i in train_idxs],\n",
    "            \"label_times_val_k\":    [val_times[i]             for i in val_idxs],\n",
    "            \"label_values_train_k\": [int(train_vals[i])       for i in train_idxs],\n",
    "            \"label_values_val_k\":   [int(val_vals[i])         for i in val_idxs],\n",
    "            \"train_idxs\":           train_idxs,\n",
    "            \"val_idxs\":             val_idxs,\n",
    "        }\n",
    "        few_shots_dict[LABELING_FUNCTION][k][rep] = entry\n",
    "\n",
    "out_json = os.path.join(TRAIN_LABELS_DIR, LABELING_FUNCTION, f\"{SHOT_STRAT}_shots_data.json\")\n",
    "os.makedirs(os.path.dirname(out_json), exist_ok=True)\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(few_shots_dict, f, ensure_ascii=False)\n",
    "\n",
    "logger.success(f\"[ok] wrote {out_json}\")\n",
    "\n",
    "def _rate(vals): return (sum(vals)/len(vals)) if vals else 0.0\n",
    "for k in k_list:\n",
    "    for rep, blob in few_shots_dict[LABELING_FUNCTION][k].items():\n",
    "        trn_n = len(blob[\"train_idxs\"]); val_n = len(blob[\"val_idxs\"])\n",
    "        trn_r = _rate(blob[\"label_values_train_k\"]); val_r = _rate(blob[\"label_values_val_k\"])\n",
    "        logger.info(f\"k={k}, rep={rep}: train={trn_n} (pos={trn_r:.3f}), val={val_n} (pos={val_r:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ehr)",
   "language": "python",
   "name": "ehr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}